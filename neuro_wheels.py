# -*- coding: utf-8 -*-
"""neuro_wheels.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PdC8uc28kz6-bvF2JUWaNg2OL6qqi2ob
"""

import streamlit as st
from transformers import GPT2LMHeadModel, GPT2Tokenizer
import torch

# Load the GPT-2 model and tokenizer
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = GPT2LMHeadModel.from_pretrained("gpt2").to(device)  # Move model to appropriate device
tokenizer = GPT2Tokenizer.from_pretrained("gpt2")

# Set padding token
tokenizer.pad_token = tokenizer.eos_token  # Use EOS token as padding token

def get_response(user_input):
    doctor_prompt = (
        "You are a compassionate and professional doctor helping individuals with mobility impairments. "
        "Your responses should always be calming, supportive, and kind, with a focus on patient care. "
        "When answering, imagine you are speaking to someone who is going through a challenging time and needs encouragement and practical advice. "
        "If the user asks about a specific health condition, provide actionable steps, recommendations, or techniques that could help them manage or assess their condition, "
        "tailored to their situation."
    )

    full_input = doctor_prompt + user_input
    inputs = tokenizer(full_input, return_tensors="pt", truncation=True, padding=True, max_length=1024)
    input_ids = inputs['input_ids'].to(device)

    try:
        with torch.no_grad():
            outputs = model.generate(input_ids, max_length=1150, num_return_sequences=1, no_repeat_ngram_size=3, top_p=0.92, temperature=0.7, do_sample=True)
        response = tokenizer.decode(outputs[0], skip_special_tokens=True)
        response = response.replace(doctor_prompt, "").strip()
        return response
    except Exception as e:
        st.error(f"Error generating response: {e}")
        return "Sorry, something went wrong. Please try again."

# Streamlit page configuration
st.set_page_config(page_title="NeuroWheels - Chat with NeuroGuide", layout="wide")
st.title("ðŸ§  NeuroWheels")

# Chatbot Section (NeuroGuide)
st.header("ðŸ¤– NeuroGuide - Your Brainy Assistant")

# User input field
user_input = st.text_input("Ask NeuroGuide anything...")

if user_input:
    # Get response from the model
    bot_response = get_response(user_input)
    st.write(f"User: {user_input}")
    st.write(f"NeuroGuide: {bot_response}")
